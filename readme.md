<div align="center">    
  <img src="https://github.com/YANGZX22/Voot/blob/main/entry/src/main/resources/base/media/title.png" width="300px">
</div>

# Voot â€“ LLM-powered Live Translation for HarmonyOS

Voot, standing for "**Vo**ice **O**n **T**op," is an intelligent simultaneous-interpretation & text translation app for **HarmonyOS**, powered by **your own LLM / translation APIs**.  
It is designed with three core principles: **security, privacy, and simplicity**.

> [!NOTE]
> Voot does not provide or resell any LLM/translation service.  
> You bring your own API keys (OpenAI, DeepL, Ollama, è±†åŒ…, etc.).


## Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Screenshots](#screenshots)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Clone](#clone)
  - [Run](#run)
- [Install Hap](#install-hap)
- [Configuration](#configuration)
  - [API Providers](#api-providers)
  - [Target Languages](#target-languages)
- [Usage](#usage)
- [Security & Privacy](#security--privacy)
- [Roadmap](#roadmap)
- [Blueprints](#blueprints)
- [Contributing](#contributing)
- [Model Performance](#model-performance)
- [Known Issues](#known-issues)
- [Acknowledgements](#acknowledgements)
- [License](#license)
- [Disclaimer](#disclaimer)


## Features

- ğŸ” **Secure by design**
  - No built-in or hosted model â€“ you must configure your own API keys.
  - API keys are stored **only in the HarmonyOS sandbox**, protected by **face / biometric unlock**.
  - No third-party analytics SDKs.

- ğŸ•µï¸ **Privacy-first**
  - Audio is processed **locally** on-device for capture & pre-processing.
  - Recorded audio for translation is **not uploaded** and is **destroyed after processing**.
  - Only the minimal text required for translation is sent directly to the provider you configure.

- ğŸ§© **Multi-provider support**
  - OpenAI (GPT-style chat / translation)
  - DeepL
  - Ollama (local LLM gateway)
  - è±†åŒ… / other custom endpoints (via configurable URL & API key)

- ğŸ—£ï¸ **Simultaneous interpretation**
  - One-tap start/stop of â€œliveâ€ translation.
  - Clear split between **original text** and **translated text**.

- ğŸŒ **Flexible language configuration**
  - Global â€œtarget languageâ€ selector.
  - Per-API configuration (prompt, system instructions, etc.).
- ğŸ“š **Glossary / Terminology Support**
  - Define custom term pairs (e.g., `HarmonyOS=é¸¿è’™`) to force specific translations.
  - Injected directly into the LLM system prompt for high adherence.

- ğŸ”„ **Device Continuation (æµè½¬)**
  - Seamlessly transfer your active translation session to another HarmonyOS device (e.g., from Phone to Tablet).
  - Keeps your current transcription and translation context intact.

- ğŸ“‚ **History & Favorites**
  - Automatically saves your translation sessions locally.
  - Review past conversations and star â­ important ones for quick access.
- ğŸ›ï¸ **Token Usage Analytics**
  - Track your API usage and costs in real-time.
  - Visual charts for daily/weekly consumption.
  - Desktop widgets to monitor usage at a glance.

- ğŸ–¼ï¸ **Picture-in-Picture (PiP) Subtitles**
  - Floating subtitle window that works over other apps.
  - Resizable and movable overlay for seamless multitasking.

- ğŸ“± **Desktop Widgets**
  - **Control Card**: Start/stop subtitle and interpretation directly from the home screen.
  - **Token Card**: Monitor your API token usage without opening the app.

- ğŸ’¡ **Simple UI, ArkTS only**
  - Frontend written purely in **ArkTS**, no extra UI framework.
  - Minimalist layout: buttons, text, and light effects â€“ optimized for real-time usage.


## Architecture


```
Voot/
â”œâ”€ entry/
â”‚  â”œâ”€ src/main/ets/
â”‚  â”‚  â”œâ”€ pages/            # ArkUI pages (Index, Configuration, Translation, Settings, etc.)
â”‚  â”‚  â”œâ”€ services/         # Mic + ASR services (SherpaWhisperMicService, PipSubtitleManager)
â”‚  â”‚  â”œâ”€ storage/          # Preference-backed stores (API config, TokenUsage, etc.)
â”‚  â”‚  â”œâ”€ components/       # Shared UI builders (PolicySheet, TokenUsageChart, etc.)
â”‚  â”‚  â”œâ”€ widget/           # Service Cards (Desktop Widgets)
â”‚  â”‚  â”œâ”€ entryformability/ # Widget lifecycle management
â”‚  â”‚  â””â”€ workers/          # Background ASR workers for long-running capture
â”‚  â”œâ”€ src/main/resources/  # Raw HTML, media assets, Sherpa models
â”‚  â”œâ”€ oh-package*.json5    # Module package definitions
â”‚  â””â”€ build-profile.json5  # Entry module build settings
â”œâ”€ AppScope/               # Application-level configuration and assets
â”œâ”€ hvigorfile.ts           # Workspace hvigor build script
â””â”€ build-profile.json5     # Global build profile
```

## Screenshots

<div align="center">    
  <img src="https://github.com/YANGZX22/Voot/blob/main/entry/src/main/resources/base/media/screenshot.jpg">
</div>


## Getting Started

### Prerequisites

* HarmonyOS toolchain:

  * DevEco Studio with ArkTS support
  * HarmonyOS SDK (version matching the project)
* A HarmonyOS device or emulator
* One or more API keys, for example:

  * OpenAI API key
  * DeepL API key
  * Ollama endpoint running locally or on LAN
  * è±†åŒ… / other compatible HTTP API

### Clone

```bash
git clone https://github.com/YANGZX22/Voot.git
cd Voot
```

Open the project in [**DevEco Studio**](https://developer.huawei.com/consumer/cn/deveco-studio/).

### Run

1. Connect a HarmonyOS device or start an emulator.
2. In DevEco Studio, select the run configuration corresponding to the app.
3. Click **Run** to build and deploy.


## Install Hap

Or you can use [Auto-installer](https://github.com/likuai2010/auto-installer/) or [DevEcho Testing](https://developer.huawei.com/consumer/cn/deveco-testing/) for installation.

> [!IMPORTANT]
> Huawei's signing servers block IP addresses outside mainland China. To sideload software for HarmonyOS NEXT in countries/regions outside mainland China.

> [!NOTE]
> Apps sideloaded via self-signing on HarmonyOS NEXT have a default validity period of 14 days. Completing [Developer Real-Name Authentication](https://developer.huawei.com/consumer/cn/verified/enrollment) extends this period to 180 days.


## Configuration

### API Providers

In the **â€œé…ç½® API / Configure APIâ€** tab:
1. Choose the current provider (e.g. OpenAI, DeepL, Ollama, è±†åŒ…).
2. Tap **â€œé…ç½® API / Configure APIâ€**.
3. For each provider, fill in:

   * **API URL** (e.g. `https://api.openai.com/v1/chat/completions`,
     `https://api-free.deepl.com/v2/translate`, or your Ollama endpoint)
   * **API Key / Token**
   * Optional: custom **prompt / system message** used for translation.

The configuration is stored **locally** in the sandbox and bound to face / biometric verification when accessing/modifying.

### Target Languages

In the **â€œç›®æ ‡è¯­è¨€ / Target languageâ€** section:

1. Select your default output language (e.g. ä¸­æ–‡, English, etc.).
2. The chosen target language is used for all translation APIs by default.

### Glossary / Terminology

In the **â€œæœ¯è¯­åº“ / Glossaryâ€** menu:

1. Enter term pairs in the format `Original=Translation` (one per line).
2. Example:
   ```text
   HarmonyOS=é¸¿è’™
   AI=äººå·¥æ™ºèƒ½
   ```
3. These terms are automatically appended to the system prompt, instructing the LLM to strictly follow your terminology.


## Usage

1. Launch **Voot** on your HarmonyOS device.
2. In the **é…ç½® API** tab:

   * Pick an API provider.
   * Configure API URL + Key.
   * Set your target language.
3. Go to the **ç¿»è¯‘ / Translate** tab:

   * Tap **â€œå¼€å¯éº¦å…‹é£â€** to start capturing audio.
   * Speak in the source language.
4. The UI will show:

   * **åŸå§‹æ–‡æœ¬** (recognized source text)
   * **ç¿»è¯‘æ–‡æœ¬** (translated result)

Use it as a live interpreter in meetings, lectures, or travel scenarios.


## Security & Privacy

Short summary (see in-app privacy policy / `PRIVACY.html` for details):

* Audio:

  * Recorded only on device for the current translation session.
  * Not uploaded to our servers (we have none).
  * Discarded after processing.
* API Keys:

  * Stored in the app sandbox.
  * Protected with HarmonyOS face/biometric mechanisms.
  * Never transmitted to any server except the provider you configured.
* Data Flow:

  * Text is sent only to your chosen provider (OpenAI / DeepL / etc.).
  * No central logging, analytics, or telemetry from the developer.


## Roadmap

Finished / planned / possible steps:

* Subtitle (Realized âœ…) 
* Live Window on HarmonyOS (Realized âœ…) 
* Desktop Widgets (Realized âœ…)
* Token usage analytics (Realized âœ…)
* Glossary / Terminology Support (Realized âœ…)
* Device Continuation (Realized âœ…)
* History & Favorites (Realized âœ…)
* Support for more LLM / translation APIs (e.g. Google Translate)
* Enhanced ASR and cutoff logic
* More supported original languages

Feel free to open issues or PRs with feature requests.

## Blueprints

### 1. Audio-Direct Multimodal 
Moving beyond "Speech-to-Text-to-Translation" lossy pipelines:
*   **Direct Audio Input**
Sending VAD-filtered audio segments directly to multimodal models (e.g., GPT-4o Audio, Gemini 1.5 Pro).
*   **Nuance Capture**
Preserving tone, emotion (sarcasm, urgency), and speaker identity which are often lost in ASR.
*   **Feedback Loop**
Using the rich understanding from the multimodal engine to "feed back" into the frontend, correcting previous ASR errors or updating the context for the Fast Track.

### 2. Confidence Scoring & Visual Feedback
*   Implement a confidence scoring system that highlights translated text based on the model's certainty.
*   Low-confidence segments could be visually marked (e.g., colored or underlined), prompting users to review or wait for the Slow Track refinement.


## Contributing

Contributions are welcome!

1. Fork the repo.
2. Create a new branch for your feature/bugfix.
3. Make changes and add tests where appropriate.
4. Submit a pull request with a clear description and screenshots if UI-related.

Before submitting, please:

* Do not commit any real API keys or secrets.
* Ensure the app builds and runs on the current HarmonyOS SDK version.

## Model Performance

* Well performed LLM/Translating models on this APP by testing:

  * OpenAI: gpt-4o-mini (preferredğŸ‘), gpt-4o
  * DeepL: Free and Pro are both well performed (preferredğŸ‘)
  * è±†åŒ…ï¼ˆç«å±±å¼•æ“ï¼‰: DeepSeek v3.2 (deepseek-v3-2-251201) (preferredğŸ‘)

* Badly performed LLM/Translating models on this APP by testing:

  * OpenAI: gpt-5 and all thinking models series
  * è±†åŒ…ï¼ˆç«å±±å¼•æ“ï¼‰: Doubao-Seed-1.6-lite (doubao-seed-1-6-lite-251015)

## Known Issues

* ASR accuracy may vary based on background noise and microphone quality.
* Some API providers may have rate limits or usage costs; monitor your usage carefully.
* ~~When tap **ä¼ è¯‘** button in desktop widget, the app may not open interpretation correctly due to HarmonyOS restrictions.~~ [Fixed]
* ~~Subtitle floating window may have layout issues on certain screen sizes, e.g. Pad.~~ [Fixed]
  You can try to adjust the size of the floating window manually. An update may fix this in the future.
* Doubao API always gives latente responses when use Lite models. This may be due to the server side of Doubao, not the app itself. [To be confirmed]

## Acknowledgements

- Inspiration: https://github.com/SakiRinn/LiveCaptions-Translator (Windows live captions translator).
- This project is an independent implementation and does not reuse any code from that repository.

## License

This project is licensed under the **GNU General Public License v3.0 (GPL-3.0)**.

Please see the [`LICENSE`](LICENSE) file in this repository for full license text.

## Disclaimer

Voot is an independent open-source project.

* It is **not affiliated with or endorsed by** OpenAI, DeepL, Ollama, è±†åŒ…, or any other API provider.
* You are responsible for:

  * Complying with the terms of the APIs you connect to.
  * Any costs generated by your API usage.
  * Ensuring that your use of Voot and third-party services complies with local laws and regulations.
